{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from traj_dataset import TrajDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "\n",
    "def posemb_sincos_3d(patches, temperature = 10000, dtype = torch.float32):\n",
    "    _, f, h, w, dim, device, dtype = *patches.shape, patches.device, patches.dtype\n",
    "\n",
    "    z, y, x = torch.meshgrid(\n",
    "        torch.arange(f, device=device),\n",
    "        torch.arange(h, device=device),\n",
    "        torch.arange(w, device=device),\n",
    "        indexing='ij')\n",
    "\n",
    "    fourier_dim = dim // 6\n",
    "\n",
    "    omega = torch.arange(fourier_dim, device = device) / (fourier_dim - 1)\n",
    "    omega = 1. / (temperature ** omega)\n",
    "\n",
    "    z = z.flatten()[:, None] * omega[None, :]\n",
    "    y = y.flatten()[:, None] * omega[None, :]\n",
    "    x = x.flatten()[:, None] * omega[None, :]\n",
    "\n",
    "    pe = torch.cat((x.sin(), x.cos(), y.sin(), y.cos(), z.sin(), z.cos()), dim = 1)\n",
    "\n",
    "    pe = F.pad(pe, (0, dim - (fourier_dim * 6))) # pad if feature dimension not cleanly divisible by 6\n",
    "    return pe.type(dtype)\n",
    "\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, out_dim=None):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, out_dim if out_dim else dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads=heads, dim_head=dim_head),\n",
    "                FeedForward(dim, mlp_dim)\n",
    "            ]))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleViT(nn.Module):\n",
    "\n",
    "    def __init__(self, *, image_size=(136, 178), image_patch_size=(68, 89), frames=4, frame_patch_size=2, dim, depth=6, heads=8, mlp_dim=512, channels=1, dim_head=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(image_patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        assert frames % frame_patch_size == 0, 'Frames must be divisible by the frame patch size'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width) * (frames // frame_patch_size)\n",
    "        patch_dim = channels * patch_height * patch_width * frame_patch_size\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b (f pf) (h p1) (w p2) -> b f h w (p1 p2 pf)', p1=patch_height, p2=patch_width, pf=frame_patch_size),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim).to(self.device)\n",
    "\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.linear_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, 24)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoderLayer = nn.TransformerDecoderLayer(d_model=2048,nhead=8).to(self.device)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoderLayer,6).to(self.device)\n",
    "\n",
    "        self.outputLinear = nn.Linear(dim,4).to(self.device)\n",
    "\n",
    "    def forward(self, video):\n",
    "        *_, h, w, dtype = *video.shape, video.dtype\n",
    "        video = video.to(self.device)\n",
    "        x = self.to_patch_embedding(video).to(self.device)\n",
    "        pe = posemb_sincos_3d(x)\n",
    "        x = rearrange(x, 'b ... d -> b (...) d') + pe\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = self.generate_sequence(x)\n",
    "        x = self.outputLinear(x)\n",
    "        return x\n",
    "\n",
    "    def generate_sequence(self, memory, max_length=6):\n",
    "        # Initialize the decoder input with a special start-of-sequence token\n",
    "        decoder_input = torch.ones((1,10, 2048)).to(self.device)\n",
    "\n",
    "        # Initialize the decoder hidden state with the encoder output\n",
    "        decoder_hidden = memory.transpose(0, 1)\n",
    "\n",
    "        # Initialize a list to store the generated sequence\n",
    "        generated_sequence = []\n",
    "\n",
    "        # Generate the output sequence token by token\n",
    "        for i in range(max_length):\n",
    "            # Pass the decoder input and hidden state through the decoder\n",
    "            decoder_output = self.decoder(tgt=decoder_input, memory=decoder_hidden)\n",
    "\n",
    "            # Select the token with the highest probability as the output token\n",
    "\n",
    "            # Append the output token to the generated sequence\n",
    "            generated_sequence.append(decoder_output)\n",
    "\n",
    "            # Use the output token as the input to the next decoder step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Concatenate the generated sequence along the time dimension\n",
    "        generated_sequence = torch.cat(generated_sequence, dim=0)\n",
    "        generated_sequence = generated_sequence.transpose(0,1)\n",
    "\n",
    "        return generated_sequence\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "opening track 0\n",
      "opening track 1\n",
      "opening track 2\n",
      "opening track 3\n",
      "opening track 4\n",
      "opening track 5\n",
      "opening track 6\n",
      "opening track 7\n",
      "opening track 8\n",
      "opening track 9\n",
      "opening track 10\n",
      "opening track 11\n",
      "opening track 12\n",
      "opening track 13\n",
      "opening track 14\n",
      "opening track 15\n",
      "opening track 16\n",
      "opening track 17\n",
      "opening track 18\n",
      "opening track 19\n",
      "opening track 20\n",
      "opening track 21\n",
      "opening track 22\n",
      "opening track 23\n",
      "opening track 24\n",
      "opening track 25\n",
      "opening track 26\n",
      "opening track 27\n",
      "opening track 28\n",
      "opening track 29\n",
      "opening track 30\n",
      "opening track 31\n",
      "opening track 32\n",
      "opening track 33\n",
      "opening track 34\n",
      "opening track 35\n",
      "opening track 36\n",
      "opening track 37\n",
      "opening track 38\n",
      "opening track 39\n",
      "opening track 40\n",
      "opening track 41\n",
      "opening track 42\n",
      "opening track 43\n",
      "opening track 44\n",
      "opening track 45\n",
      "opening track 46\n",
      "opening track 47\n",
      "opening track 48\n",
      "opening track 49\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "    model = SimpleViT(dim=2048)\n",
    "    dataset = TrajDataset(\"datasets/bookstore/video0\", device, img_step=10)\n",
    "\n",
    "\n",
    "    optim = Adam(params=model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "criterion = MSELoss()\n",
    "\n",
    "loss_evol = []\n",
    "\n",
    "test_loss = []\n",
    "for epoch in range(1):\n",
    "    print(\"Starting epoch: \", epoch)\n",
    "    for id_b, batch in enumerate(train_loader):\n",
    "        print(f\"Batch {id_b}\")\n",
    "        if len(batch[\"X\"]) != batch_size: continue\n",
    "\n",
    "        model.train()\n",
    "        X_train = batch[\"X\"][:-10]\n",
    "        Y_train = batch[\"Y\"][:-10]\n",
    "\n",
    "        X_test = batch[\"X\"][-10:]\n",
    "        Y_test = batch[\"Y\"][-10:]\n",
    "        pred = model(X_train.to(device))\n",
    "        l = criterion(pred, Y_train.to(device))\n",
    "        loss_evol.append(l.item())\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "\n",
    "print(loss_evol)\n",
    "plt.plot(loss_evol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
