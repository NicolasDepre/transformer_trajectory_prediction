{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-17T14:28:47.323328Z",
     "end_time": "2023-04-17T14:28:47.340491Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from traj_dataset import TrajDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "\n",
    "def posemb_sincos_3d(patches, temperature = 10000, dtype = torch.float32):\n",
    "    _, f, h, w, dim, device, dtype = *patches.shape, patches.device, patches.dtype\n",
    "\n",
    "    z, y, x = torch.meshgrid(\n",
    "        torch.arange(f, device=device),\n",
    "        torch.arange(h, device=device),\n",
    "        torch.arange(w, device=device),\n",
    "        indexing='ij')\n",
    "\n",
    "    fourier_dim = dim // 6\n",
    "\n",
    "    omega = torch.arange(fourier_dim, device = device) / (fourier_dim - 1)\n",
    "    omega = 1. / (temperature ** omega)\n",
    "\n",
    "    z = z.flatten()[:, None] * omega[None, :]\n",
    "    y = y.flatten()[:, None] * omega[None, :]\n",
    "    x = x.flatten()[:, None] * omega[None, :]\n",
    "\n",
    "    pe = torch.cat((x.sin(), x.cos(), y.sin(), y.cos(), z.sin(), z.cos()), dim = 1)\n",
    "\n",
    "    pe = F.pad(pe, (0, dim - (fourier_dim * 6))) # pad if feature dimension not cleanly divisible by 6\n",
    "    return pe.type(dtype)\n",
    "\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, out_dim=None):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, out_dim if out_dim else dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads=heads, dim_head=dim_head),\n",
    "                FeedForward(dim, mlp_dim)\n",
    "            ]))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleViT(nn.Module):\n",
    "\n",
    "    def __init__(self, *, image_size=(136, 178), image_patch_size=(68, 89), frames=4, frame_patch_size=2, dim, depth=6, heads=8, mlp_dim=512, channels=1, dim_head=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(image_patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        assert frames % frame_patch_size == 0, 'Frames must be divisible by the frame patch size'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width) * (frames // frame_patch_size)\n",
    "        patch_dim = channels * patch_height * patch_width * frame_patch_size\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b (f pf) (h p1) (w p2) -> b f h w (p1 p2 pf)', p1=patch_height, p2=patch_width, pf=frame_patch_size),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim).to(self.device)\n",
    "\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.linear_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, 24)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoderLayer = nn.TransformerDecoderLayer(d_model=2048,nhead=8).to(self.device)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoderLayer,6).to(self.device)\n",
    "\n",
    "        self.outputLinear = nn.Linear(dim,4).to(self.device)\n",
    "\n",
    "    def forward(self, video):\n",
    "        *_, h, w, dtype = *video.shape, video.dtype\n",
    "        video = video.to(self.device)\n",
    "        x = self.to_patch_embedding(video).to(self.device)\n",
    "        pe = posemb_sincos_3d(x)\n",
    "        x = rearrange(x, 'b ... d -> b (...) d') + pe\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = self.generate_sequence(x)\n",
    "        x = self.outputLinear(x)\n",
    "        return x\n",
    "\n",
    "    def generate_sequence(self, memory, max_length=6):\n",
    "        # Initialize the decoder input with a special start-of-sequence token\n",
    "        decoder_input = torch.ones((1,10, 2048)).to(self.device)\n",
    "\n",
    "        # Initialize the decoder hidden state with the encoder output\n",
    "        decoder_hidden = memory.transpose(0, 1)\n",
    "\n",
    "        # Initialize a list to store the generated sequence\n",
    "        generated_sequence = []\n",
    "\n",
    "        # Generate the output sequence token by token\n",
    "        for i in range(max_length):\n",
    "            # Pass the decoder input and hidden state through the decoder\n",
    "            decoder_output = self.decoder(tgt=decoder_input, memory=decoder_hidden)\n",
    "\n",
    "            # Select the token with the highest probability as the output token\n",
    "\n",
    "            # Append the output token to the generated sequence\n",
    "            generated_sequence.append(decoder_output)\n",
    "\n",
    "            # Use the output token as the input to the next decoder step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Concatenate the generated sequence along the time dimension\n",
    "        generated_sequence = torch.cat(generated_sequence, dim=0)\n",
    "        generated_sequence = generated_sequence.transpose(0,1)\n",
    "\n",
    "        return generated_sequence\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "opening track 0\n",
      "opening track 1\n",
      "opening track 2\n",
      "opening track 3\n",
      "opening track 4\n",
      "opening track 5\n",
      "opening track 6\n",
      "opening track 7\n",
      "opening track 8\n",
      "opening track 9\n",
      "opening track 10\n",
      "opening track 11\n",
      "opening track 12\n",
      "opening track 13\n",
      "opening track 14\n",
      "opening track 15\n",
      "opening track 16\n",
      "opening track 17\n",
      "opening track 18\n",
      "opening track 19\n",
      "opening track 20\n",
      "opening track 21\n",
      "opening track 22\n",
      "opening track 23\n",
      "opening track 24\n",
      "opening track 25\n",
      "opening track 26\n",
      "opening track 27\n",
      "opening track 28\n",
      "opening track 29\n",
      "opening track 30\n",
      "opening track 31\n",
      "opening track 32\n",
      "opening track 33\n",
      "opening track 34\n",
      "opening track 35\n",
      "opening track 36\n",
      "opening track 37\n",
      "opening track 38\n",
      "opening track 39\n",
      "opening track 40\n",
      "opening track 41\n",
      "opening track 42\n",
      "opening track 43\n",
      "opening track 44\n",
      "opening track 45\n",
      "opening track 46\n",
      "opening track 47\n",
      "opening track 48\n",
      "opening track 49\n",
      "opening track 50\n",
      "opening track 51\n",
      "opening track 52\n",
      "opening track 53\n",
      "opening track 54\n",
      "opening track 55\n",
      "opening track 56\n",
      "opening track 57\n",
      "opening track 58\n",
      "opening track 59\n",
      "opening track 60\n",
      "opening track 61\n",
      "opening track 62\n",
      "opening track 63\n",
      "opening track 64\n",
      "opening track 65\n",
      "opening track 66\n",
      "opening track 67\n",
      "opening track 68\n",
      "opening track 69\n",
      "opening track 70\n",
      "opening track 71\n",
      "opening track 72\n",
      "opening track 73\n",
      "opening track 74\n",
      "opening track 75\n",
      "opening track 76\n",
      "opening track 77\n",
      "opening track 78\n",
      "opening track 79\n",
      "opening track 80\n",
      "opening track 81\n",
      "opening track 82\n",
      "opening track 83\n",
      "opening track 84\n",
      "opening track 85\n",
      "opening track 86\n",
      "opening track 87\n",
      "opening track 88\n",
      "opening track 89\n",
      "opening track 90\n",
      "opening track 91\n",
      "opening track 92\n",
      "opening track 93\n",
      "opening track 94\n",
      "opening track 95\n",
      "opening track 96\n",
      "opening track 97\n",
      "opening track 98\n",
      "opening track 99\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "    model = SimpleViT(dim=1024)\n",
    "    dataset = TrajDataset(\"datasets/bookstore/video0\", device, img_step=10)\n",
    "\n",
    "    optim = Adam(params=model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T14:30:47.964448Z",
     "end_time": "2023-04-17T14:33:15.236266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Batch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[8, 80, 256]' is invalid for input of size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-c4462f9ddc7d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mX_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"X\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[0mY_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Y\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m         \u001B[0mpred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m         \u001B[0ml\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mloss_evol\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ml\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-fef152db096e>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, video)\u001B[0m\n\u001B[0;32m    150\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransformer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 152\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerate_sequence\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    153\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputLinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-fef152db096e>\u001B[0m in \u001B[0;36mgenerate_sequence\u001B[1;34m(self, memory, max_length)\u001B[0m\n\u001B[0;32m    167\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_length\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    168\u001B[0m             \u001B[1;31m# Pass the decoder input and hidden state through the decoder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 169\u001B[1;33m             \u001B[0mdecoder_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtgt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdecoder_input\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmemory\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdecoder_hidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    170\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    171\u001B[0m             \u001B[1;31m# Select the token with the highest probability as the output token\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\transformer.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[0;32m    331\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    332\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmod\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 333\u001B[1;33m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001B[0m\u001B[0;32m    334\u001B[0m                          \u001B[0mmemory_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmemory_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    335\u001B[0m                          \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtgt_key_padding_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\transformer.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[0;32m    650\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    651\u001B[0m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sa_block\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtgt_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtgt_key_padding_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 652\u001B[1;33m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mha_block\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmemory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmemory_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmemory_key_padding_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    653\u001B[0m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_ff_block\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    654\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\transformer.py\u001B[0m in \u001B[0;36m_mha_block\u001B[1;34m(self, x, mem, attn_mask, key_padding_mask)\u001B[0m\n\u001B[0;32m    667\u001B[0m     def _mha_block(self, x: Tensor, mem: Tensor,\n\u001B[0;32m    668\u001B[0m                    attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n\u001B[1;32m--> 669\u001B[1;33m         x = self.multihead_attn(x, mem, mem,\n\u001B[0m\u001B[0;32m    670\u001B[0m                                 \u001B[0mattn_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattn_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    671\u001B[0m                                 \u001B[0mkey_padding_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkey_padding_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\activation.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001B[0m\n\u001B[0;32m   1165\u001B[0m                 v_proj_weight=self.v_proj_weight, average_attn_weights=average_attn_weights)\n\u001B[0;32m   1166\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1167\u001B[1;33m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001B[0m\u001B[0;32m   1168\u001B[0m                 \u001B[0mquery\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membed_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_heads\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1169\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0min_proj_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0min_proj_bias\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mmulti_head_attention_forward\u001B[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001B[0m\n\u001B[0;32m   5095\u001B[0m     \u001B[0mq\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontiguous\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtgt_len\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbsz\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnum_heads\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhead_dim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5096\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mstatic_k\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5097\u001B[1;33m         \u001B[0mk\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontiguous\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbsz\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnum_heads\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhead_dim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5098\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5099\u001B[0m         \u001B[1;31m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[8, 80, 256]' is invalid for input of size 0"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "n_epochs = 1\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "criterion = MSELoss()\n",
    "\n",
    "loss_evol = []\n",
    "\n",
    "test_loss = []\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Starting epoch: \", epoch)\n",
    "    for id_b, batch in enumerate(train_loader):\n",
    "        print(f\"Batch {id_b}\")\n",
    "        if len(batch[\"X\"]) != batch_size: continue\n",
    "\n",
    "        model.train()\n",
    "        X_train = batch[\"X\"][:-10]\n",
    "        Y_train = batch[\"Y\"][:-10]\n",
    "\n",
    "        X_test = batch[\"X\"][-10:]\n",
    "        Y_test = batch[\"Y\"][-10:]\n",
    "        pred = model(X_train.to(device))\n",
    "        l = criterion(pred, Y_train.to(device))\n",
    "        loss_evol.append(l.item())\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "\n",
    "print(loss_evol)\n",
    "plt.plot(loss_evol)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
