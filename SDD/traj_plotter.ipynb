{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from traj_dataset import TrajDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from model import SimpleViT\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get run\n",
    "run_id = \"97y0w076\"\n",
    "run = api.run(\"/depren/thesis_official_runs/runs/\" + run_id)\n",
    "\n",
    "# load model\n",
    "conf = run.config\n",
    "\n",
    "model = SimpleViT(dim=conf['model_dimension'],\n",
    "                  device=conf['device'],\n",
    "                  mlp_dim=conf['mlp_dimension'],\n",
    "                  image_size=(conf['image_size'], conf['image_size']),\n",
    "                  image_patch_size=(conf['patch_size'], conf['patch_size']),\n",
    "                  frame_patch_size=conf['patch_dept'],\n",
    "                  frames=conf['n_prev'],\n",
    "                  depth=conf['model_depth'],\n",
    "                  heads=conf['heads'],\n",
    "                  )\n",
    "\n",
    "model.load_state_dict(torch.load(conf['save_name']))\n",
    "\n",
    "data_config = run.config['dataset']\n",
    "folders = TrajDataset.conf_to_folders(data_config)\n",
    "size = f\"{conf['image_size']}_{conf['image_size']}_{conf['block_size']}\"\n",
    "data_folders = [\"/waldo/walban/student_datasets/arfranck/SDD/scenes/\" + folder + size for folder in folders]\n",
    "\n",
    "\n",
    "props = [conf['train_prop'], conf['val_prop'], conf['test_prop']]\n",
    "n_prev = conf['n_prev']\n",
    "n_next = conf['n_next']\n",
    "img_step = conf['img_step']\n",
    "train_data = TrajDataset(data_folders, n_prev=n_prev, n_next=n_next, img_step=img_step, prop=props, part=0)\n",
    "val_data = TrajDataset(data_folders, n_prev=n_prev, n_next=n_next, img_step=img_step, prop=props, part=1)\n",
    "test_data = TrajDataset(data_folders, n_prev=n_prev, n_next=n_next, img_step=img_step, prop=props, part=2)\n",
    "\n",
    "batch_size=conf['batch_size']\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for id_b2, batch_test in enumerate(test_loader):\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f\"Test Batch {id_b2}\")\n",
    "        model.eval()\n",
    "\n",
    "        X_test = batch_test[\"src\"]\n",
    "        Y_test = batch_test[\"tgt\"]\n",
    "\n",
    "\n",
    "        X_coords = batch_test[\"coords\"]\n",
    "\n",
    "        print(X_coords.shape)\n",
    "        future = None\n",
    "\n",
    "        for k in range(8):\n",
    "            pred,output = model(X_test.to(device),future,train=False)\n",
    "            future = output\n",
    "\n",
    "        print(criterion(pred[0],Y_test[0].to(device)).item())\n",
    "        prev = [(k[0]*64,k[1]*64) for k in X_coords[0]]\n",
    "        points = [(k[0]*64,k[1]*64) for k in Y_test[0]]\n",
    "        points2 = [(k[0]*64,k[1]*64) for k in pred[0].cpu().detach().numpy()]\n",
    "\n",
    "        prev_x,prev_y = zip(*prev)\n",
    "        x,y = zip(*points)\n",
    "        x2,y2 = zip(*points2)\n",
    "        print(len(points))\n",
    "\n",
    "        plt.scatter([k for k in prev_x],[k for k in prev_y], label=\"Prev\")\n",
    "        plt.scatter([k for k in x],[k for k in y], label=\"Truth\")\n",
    "        plt.scatter([k for k in x2],[k for k in y2],label=\"Prediction\",color=([\"blue\" for k in range(7)] + [\"black\"]))\n",
    "        #plt.imread(\"reference.jpg\")\n",
    "        plt.legend()\n",
    "        plt.xlim(0,64)\n",
    "        plt.ylim(0,64)\n",
    "        #plt.imshow(plt.imread(\"reference.jpg\"))\n",
    "\n",
    "        plt.savefig(\"/waldo/walban/student_datasets/arfranck/SDD/plots/test_3.pdf\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
